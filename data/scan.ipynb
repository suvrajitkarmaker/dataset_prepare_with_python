{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "path = 'H:\\/Final year project\\/Suvrrajit\\/dataset\\/col\\/119/'\n",
    "path22 = 'H:\\/Final year project\\/Suvrrajit\\/dataset\\/squreerase\\/check/'\n",
    "\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "for items in dirs:\n",
    "    try:\n",
    "        cv2.imwrite(path22+items,process_image_for_ocr(path+items))\n",
    "    except Exception as e:\n",
    "        print(items , e)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "path = 'H:\\/Final year project\\/male\\/col/'\n",
    "path22 = 'H:\\/Final year project\\/male\\/bw/'\n",
    "\n",
    "\n",
    "for i in range(0,120):\n",
    "    dirs = os.listdir(path+'/'+str(i)+'/')\n",
    "    for items in dirs:\n",
    "        try:\n",
    "            cv2.imwrite(path22+'/'+str(i)+'/'+items,process_image_for_ocr(path+'/'+str(i)+'/'+items))\n",
    "        except Exception as e:\n",
    "            print(items , e)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\/Final year project\\/male\\/bw//117/0_CHA_15_1_915.jpg fail\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def saveing(x, y, w, h,path2,items,img):\n",
    "    crop = img[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    i = Image.fromarray(crop)\n",
    "    i.save(path2+items, \"JPEG\", quality=100, optimize=True, progressive=True) \n",
    "\n",
    "pa = 'H:\\/Final year project\\/male\\/bw/'\n",
    "pa2 = 'H:\\/Final year project\\/male\\/adjust/'\n",
    "for i in range(0,120):\n",
    "    path=pa+'/'+str(i)+'/'\n",
    "    path22=pa2+'/'+str(i)+'/'\n",
    "    dirs = os.listdir(path)\n",
    "    #print(i,end='-')\n",
    "\n",
    "    for items in dirs:\n",
    "        try:\n",
    "            x1, y1, w1, h1 = (0,0,0,0)\n",
    "            points = 0\n",
    "\n",
    "            # load image\n",
    "            img = cv2.imread(path+items) \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "#             # threshold to get just the signature\n",
    "            retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "            # find where the signature is and make a cropped region\n",
    "            points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "            points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(points) # create a rectangle around those points\n",
    "\n",
    "            try:\n",
    "                saveing(x1, y1, w1, h1,path22,items,img)\n",
    "            except:\n",
    "                print(path+items,'fail')\n",
    "        except Exception as e:\n",
    "            print(path+items)\n",
    "            raise e\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "pa = 'H:\\/Final year project\\/male\\/adjust/'\n",
    "pa2 = 'H:\\/Final year project\\/male\\/resize/'\n",
    "for i in range(0,120):\n",
    "    path=pa+'/'+str(i)+'/'\n",
    "    path22=pa2+'/'+str(i)+'/'\n",
    "    dirs = os.listdir(path)\n",
    "    #print(i,end='-')\n",
    "\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            with Image.open(path+item) as im:\n",
    "                f, e = os.path.splitext(path+item)\n",
    "                imResize = im.resize((28,28), Image.ANTIALIAS)\n",
    "                imResize.save(path22+item, \"JPEG\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = Image.fromarray(crop)\n",
    "# i.save('out.jpg', \"JPEG\", quality=100, optimize=True, progressive=True)  \n",
    "\n",
    "saveing(x, y, w, h,'','out.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_Dha_21_3_00014', 'jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = 1800\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "#     temp_filename = set_image_dpi(file_path)\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size\n",
    "    factor = max(1, int(IMAGE_SIZE / length_x))\n",
    "    size = factor * length_x, factor * width_y\n",
    "    # size = (1800, 1800)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp_filename = temp_file.name\n",
    "    im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename\n",
    "\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process_image_for_ocr('out.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv2.imshow('OUTPUT',process_image_for_ocr('out.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite('output/m_u (22).jpg',process_image_for_ocr('m_u (2).jpg'))\n",
    "# # cv2.imwrite('jpg/newdpi.jpg',set_image_dpi('out.jpeg'))\n",
    "# # cv2.imwrite('jpg/newsmoth.jpg',image_smoothening('out.jpeg'))\n",
    "# # cv2.imwrite('jpg/newnoise.jpg',remove_noise_and_smooth('out.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import os\n",
    "def scan(image_path='female/error/1_Chad_21_3_00073.jpg'):\n",
    "\n",
    "    RESCALED_HEIGHT = 500.0\n",
    "    OUTPUT_DIR = 'female/error/scn'\n",
    "\n",
    "    # load the image and compute the ratio of the old height\n",
    "    # to the new height, clone it, and resize it\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    assert(image is not None)\n",
    "\n",
    "    ratio = image.shape[0] / RESCALED_HEIGHT\n",
    "    orig = image.copy()\n",
    "    rescaled_image = imutils.resize(image, height = int(RESCALED_HEIGHT))\n",
    "\n",
    "    # get the contour of the document\n",
    "    screenCnt = image\n",
    "\n",
    "#     if self.interactive:\n",
    "#         screenCnt = self.interactive_get_contour(screenCnt, rescaled_image)\n",
    "\n",
    "    # apply the perspective transformation\n",
    "#     warped = transform.four_point_transform(orig, screenCnt * ratio)\n",
    "\n",
    "    # convert the warped image to grayscale\n",
    "    gray = cv2.cvtColor(screenCnt, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sharpen image\n",
    "    sharpen = cv2.GaussianBlur(gray, (0,0), 3)\n",
    "    sharpen = cv2.addWeighted(gray, 1.5, sharpen, -0.5, 0)\n",
    "\n",
    "    # apply adaptive threshold to get black and white effect\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 41,30)\n",
    "\n",
    "    # save the transformed image\n",
    "    basename = os.path.basename(image_path)\n",
    "    cv2.imwrite(OUTPUT_DIR + '/' + basename, thresh)\n",
    "    print(\"Proccessed\" + basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessed1_Chad_21_3_00073.jpg\n"
     ]
    }
   ],
   "source": [
    "scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveing(x, y, w, h,path,img):\n",
    "    crop = img[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    i = Image.fromarray(crop)\n",
    "    i.save('3.png') \n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-29-12734bbff54a>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-12734bbff54a>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def good():\n",
    "#         print(90)\n",
    "#         x1, y1, w1, h1 = (0,0,0,0)\n",
    "#         points = 0\n",
    "\n",
    "#         # load image\n",
    "#         img = cv2.imread(path) \n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "#         retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "#         # find where the signature is and make a cropped region\n",
    "#         points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "#         points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "#         x1, y1, w1, h1 = cv2.boundingRect(points) # create a rectangle around those points\n",
    "#         try:\n",
    "#             x, y, w, h = x1-3, y1-3, w1+3, h1+3 # make the box a little bigger\n",
    "#             saveing(x, y, w, h,path,img)\n",
    "#         except Exception as e:\n",
    "#             try:\n",
    "#                 x, y, w, h = x1-2, y1-2, w1+2, h1+2 # make the box a little bigger\n",
    "#                 saveing(x, y, w, h,path,img)\n",
    "#             except Exception as e:\n",
    "#                 try:\n",
    "#                     x, y, w, h = x1-1, y1-1, w1+1, h1+1 # make the box a little bigger\n",
    "#                     saveing(x, y, w, h,path,img)\n",
    "#                 except Exception as e:\n",
    "#                     try:\n",
    "#                         x, y, w, h = x1, y1, w, h # make the box a little bigger\n",
    "#                         saveing(x, y, w, h,path,img)\n",
    "#     #                                     print(path+items,'-----')\n",
    "#                     except:\n",
    "#                         print(path+items,'fail')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sfd\n"
     ]
    }
   ],
   "source": [
    "def process_image_for_ocr(file_path,self):\n",
    "    # TODO : Implement using opencv\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "def image_smoothening(self,img):\n",
    "    ret1, th1 = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "def remove_noise_and_smooth(self,file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41,\n",
    "                                     3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image\n",
    "\n",
    "\n",
    "def scan120(self):\n",
    "#     self.raw120()\n",
    "    distD = ''\n",
    "#     g = self.gender()\n",
    "    pathn = distD \n",
    "    path2 = distD \n",
    "    for i in range(0, 120):\n",
    "        path = pathn + str(i) + '/'\n",
    "        path22 = path2 + str(i) + '/'\n",
    "\n",
    "        dirs = os.listdir(path)\n",
    "\n",
    "        for items in dirs:\n",
    "            try:\n",
    "                cv2.imwrite(path22 + items, self.process_image_for_ocr(path + items))\n",
    "            except Exception as e:\n",
    "                print(items, e)\n",
    "                raise e\n",
    "print(\"Sfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "path='H:\\/Final year project\\/male\\/male\\/0/'\n",
    "path2='H:\\/Final year project\\/male\\/invert\\/0/'\n",
    "dirs = os.listdir(path)\n",
    "for items in dirs:\n",
    "    image = Image.open(path + items)\n",
    "    inverted_image = PIL.ImageOps.invert(image)\n",
    "    inverted_image.save(path2 + items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153514\n"
     ]
    }
   ],
   "source": [
    "#imagecount\n",
    "import os\n",
    "path = 'H:\\/Final year project\\/final\\/female/'\n",
    "\n",
    "ct=0\n",
    "for i in range(0,120):\n",
    "    dirs = os.listdir(path+str(i)+'/')\n",
    "    for items in dirs:\n",
    "        ct=ct+1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
