{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'H:\\\\/Final year project\\\\/report\\\\/New folder\\\\/1/0/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ce18fae6a846>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpath22\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'H:\\\\/Final year project\\\\/report\\\\/New folder\\\\/1/0/'"
     ]
    }
   ],
   "source": [
    "pathn = 'H:\\/Final year project\\/report\\/New folder\\/1/'\n",
    "path2 = 'H:\\/Final year project\\/report\\/New folder\\/nosefree/'\n",
    "for i in range(0,120):\n",
    "    path = pathn+str(i)+'/'\n",
    "    path22 = path2+str(i)+'/'\n",
    "\n",
    "    dirs = os.listdir(path)\n",
    "\n",
    "    for items in dirs:\n",
    "        try:\n",
    "            cv2.imwrite(path22+items,process_image_for_ocr(path+items))\n",
    "        except Exception as e:\n",
    "            print(items , e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "pathn = 'H:\\Final year project\\/Suvrrajit\\/final\\/femaleScan/'\n",
    "path2 = 'H:\\Final year project\\/Suvrrajit\\/final\\/xx/'\n",
    "for i in range(0,2):\n",
    "    path = pathn+str(i)+'/'\n",
    "    path22 = path2+str(i)+'/'\n",
    "\n",
    "    dirs = os.listdir(path)\n",
    "\n",
    "    for items in dirs:\n",
    "        try:\n",
    "\n",
    "            BINARY_THREHOLD = 180\n",
    "\n",
    "\n",
    "            # load image\n",
    "            img = cv2.imread(path+items) \n",
    "            # rsz_img = cv2.resize(img, None, fx=0.25, fy=0.25) # resize since image is huge\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "            # threshold to get just the signature\n",
    "#             retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "            thresh_gray = gray\n",
    "\n",
    "\n",
    "            # find where the signature is and make a cropped region\n",
    "            points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "            points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "            x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "            x, y, w, h = x-10, y-10, w+10, h+10 # make the box a little bigger\n",
    "            crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "\n",
    "            # get the thresholded crop\n",
    "            retval, thresh_crop = cv2.threshold(crop, thresh=155, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "            # display\n",
    "#             cv2.imshow(\"Cropped and thresholded image\", thresh_crop) \n",
    "            cv2.imwrite(path22+items,thresh_crop)\n",
    "#             cv2.waitKey(0)\n",
    "        except Exception as e:\n",
    "            print(items , e)\n",
    "            \n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44-45-46-47-48-49-50-51-52-53-54-55-56-57-58-59-60-61-62-63-64-65-66-67-68-69-70-71-72-73-74-75-76-77-78-79-80-81-82-83-84-85-86-87-88-89-90-91-92-93-94-95-96-97-98-99-100-101-102-103-104-105-106-107-108-109-"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def saveing(x, y, w, h,path22,items,img):\n",
    "    crop = img[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    i = Image.fromarray(crop)\n",
    "    i.save(path22+items, \"JPEG\", quality=100, optimize=True, progressive=True) \n",
    "\n",
    "pathn = '../male/Data/M/Scan120/'\n",
    "path2 = '../male/Data/M/main120/'\n",
    "for i in range(0,120):\n",
    "    path = pathn+str(i)+'/'\n",
    "    path22 = path2+str(i)+'/'\n",
    "\n",
    "    dirs = os.listdir(path)\n",
    "    print(i,end='-')\n",
    "\n",
    "    for items in dirs:\n",
    "        try:\n",
    "            x1, y1, w1, h1 = (0,0,0,0)\n",
    "            points = 0\n",
    "\n",
    "            # load image\n",
    "            img = cv2.imread(path+items) \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "#             # threshold to get just the signature\n",
    "            retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "            # find where the signature is and make a cropped region\n",
    "            points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "            points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(points) # create a rectangle around those points\n",
    "#             x, y, w, h = x-1, y-1, w+3, h+3 # make the box a little bigger\n",
    "#             try:\n",
    "#                 x, y, w, h = x1-5, y1-5, w1+5, h1+5 # make the box a little bigger\n",
    "#                 saveing(x, y, w, h,path22,items,img)\n",
    "#             except Exception as e:                \n",
    "#                 try:\n",
    "#                     .x, y, w, h = x1-4, y1-4, w1+4, h1+4 # make the box a little bigger\n",
    "#                     .saveing(x, y, w, h,path22,items,img)\n",
    "#                 except Exception as e:\n",
    "            try:\n",
    "                x, y, w, h = x1-3, y1-3, w1+3, h1+3 # make the box a little bigger\n",
    "                saveing(x, y, w, h,path22,items,img)\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    x, y, w, h = x1-2, y1-2, w1+2, h1+2 # make the box a little bigger\n",
    "                    saveing(x, y, w, h,path22,items,img)\n",
    "                except Exception as e:\n",
    "                    try:\n",
    "                        x, y, w, h = x1-1, y1-1, w1+1, h1+1 # make the box a little bigger\n",
    "                        saveing(x, y, w, h,path22,items,img)\n",
    "                    except Exception as e:\n",
    "                        try:\n",
    "                            x, y, w, h = x1, y1, w, h # make the box a little bigger\n",
    "                            saveing(x, y, w, h,path22,items,img)\n",
    "#                                     print(path+items,'-----')\n",
    "                        except:\n",
    "                            print(path+items,'fail')\n",
    "                                \n",
    "        except Exception as e:\n",
    "            print(path+items)\n",
    "            raise e\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "p = '../croped/resized/process/femaleScan/1/1_Nar_20_3_00065.jpg'\n",
    "\n",
    "img = cv2.imread(p) \n",
    "# rsz_img = cv2.resize(img, None, fx=0.25, fy=0.25) # resize since image is huge\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "# threshold to get just the signature\n",
    "#             retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "thresh_gray = gray\n",
    "\n",
    "\n",
    "# find where the signature is and make a cropped region\n",
    "points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "x, y, w, h = x-5, y-5, w+5, h+5 # make the box a little bigger\n",
    "crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "\n",
    "# get the thresholded crop\n",
    "retval, thresh_crop = cv2.threshold(crop, thresh=155, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "            # display\n",
    "#             cv2.imshow(\"Cropped and thresholded image\", thresh_crop) \n",
    "#             cv2.imwrite(path22+items,thresh_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = Image.fromarray(crop)\n",
    "# i.save('out.jpg', \"JPEG\", quality=100, optimize=True, progressive=True)  \n",
    "\n",
    "saveing(x, y, w, h,'','out.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_Dha_21_3_00014', 'jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = 1800\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "#     temp_filename = set_image_dpi(file_path)\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size\n",
    "    factor = max(1, int(IMAGE_SIZE / length_x))\n",
    "    size = factor * length_x, factor * width_y\n",
    "    # size = (1800, 1800)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp_filename = temp_file.name\n",
    "    im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename\n",
    "\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "\n",
    "def remove_noise_and_smooth(file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process_image_for_ocr('out.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv2.imshow('OUTPUT',process_image_for_ocr('out.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite('output/m_u (22).jpg',process_image_for_ocr('m_u (2).jpg'))\n",
    "# # cv2.imwrite('jpg/newdpi.jpg',set_image_dpi('out.jpeg'))\n",
    "# # cv2.imwrite('jpg/newsmoth.jpg',image_smoothening('out.jpeg'))\n",
    "# # cv2.imwrite('jpg/newnoise.jpg',remove_noise_and_smooth('out.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import os\n",
    "def scan(image_path='female/error/1_Chad_21_3_00073.jpg'):\n",
    "\n",
    "    RESCALED_HEIGHT = 500.0\n",
    "    OUTPUT_DIR = 'female/error/scn'\n",
    "\n",
    "    # load the image and compute the ratio of the old height\n",
    "    # to the new height, clone it, and resize it\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    assert(image is not None)\n",
    "\n",
    "    ratio = image.shape[0] / RESCALED_HEIGHT\n",
    "    orig = image.copy()\n",
    "    rescaled_image = imutils.resize(image, height = int(RESCALED_HEIGHT))\n",
    "\n",
    "    # get the contour of the document\n",
    "    screenCnt = image\n",
    "\n",
    "#     if self.interactive:\n",
    "#         screenCnt = self.interactive_get_contour(screenCnt, rescaled_image)\n",
    "\n",
    "    # apply the perspective transformation\n",
    "#     warped = transform.four_point_transform(orig, screenCnt * ratio)\n",
    "\n",
    "    # convert the warped image to grayscale\n",
    "    gray = cv2.cvtColor(screenCnt, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # sharpen image\n",
    "    sharpen = cv2.GaussianBlur(gray, (0,0), 3)\n",
    "    sharpen = cv2.addWeighted(gray, 1.5, sharpen, -0.5, 0)\n",
    "\n",
    "    # apply adaptive threshold to get black and white effect\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 41,30)\n",
    "\n",
    "    # save the transformed image\n",
    "    basename = os.path.basename(image_path)\n",
    "    cv2.imwrite(OUTPUT_DIR + '/' + basename, thresh)\n",
    "    print(\"Proccessed\" + basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessed1_Chad_21_3_00073.jpg\n"
     ]
    }
   ],
   "source": [
    "scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveing(x, y, w, h,path,img):\n",
    "    crop = img[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    i = Image.fromarray(crop)\n",
    "    i.save('3.png') \n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-29-12734bbff54a>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-12734bbff54a>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def good():\n",
    "#         print(90)\n",
    "#         x1, y1, w1, h1 = (0,0,0,0)\n",
    "#         points = 0\n",
    "\n",
    "#         # load image\n",
    "#         img = cv2.imread(path) \n",
    "#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "#         retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "#         # find where the signature is and make a cropped region\n",
    "#         points = np.argwhere(thresh_gray==0) # find where the black pixels are\n",
    "#         points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "#         x1, y1, w1, h1 = cv2.boundingRect(points) # create a rectangle around those points\n",
    "#         try:\n",
    "#             x, y, w, h = x1-3, y1-3, w1+3, h1+3 # make the box a little bigger\n",
    "#             saveing(x, y, w, h,path,img)\n",
    "#         except Exception as e:\n",
    "#             try:\n",
    "#                 x, y, w, h = x1-2, y1-2, w1+2, h1+2 # make the box a little bigger\n",
    "#                 saveing(x, y, w, h,path,img)\n",
    "#             except Exception as e:\n",
    "#                 try:\n",
    "#                     x, y, w, h = x1-1, y1-1, w1+1, h1+1 # make the box a little bigger\n",
    "#                     saveing(x, y, w, h,path,img)\n",
    "#                 except Exception as e:\n",
    "#                     try:\n",
    "#                         x, y, w, h = x1, y1, w, h # make the box a little bigger\n",
    "#                         saveing(x, y, w, h,path,img)\n",
    "#     #                                     print(path+items,'-----')\n",
    "#                     except:\n",
    "#                         print(path+items,'fail')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sfd\n"
     ]
    }
   ],
   "source": [
    "def process_image_for_ocr(file_path,self):\n",
    "    # TODO : Implement using opencv\n",
    "    im_new = remove_noise_and_smooth(file_path)\n",
    "    return im_new\n",
    "\n",
    "def image_smoothening(self,img):\n",
    "    ret1, th1 = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "def remove_noise_and_smooth(self,file_name):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41,\n",
    "                                     3)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    img = image_smoothening(img)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image\n",
    "\n",
    "\n",
    "def scan120(self):\n",
    "#     self.raw120()\n",
    "    distD = ''\n",
    "#     g = self.gender()\n",
    "    pathn = distD \n",
    "    path2 = distD \n",
    "    for i in range(0, 120):\n",
    "        path = pathn + str(i) + '/'\n",
    "        path22 = path2 + str(i) + '/'\n",
    "\n",
    "        dirs = os.listdir(path)\n",
    "\n",
    "        for items in dirs:\n",
    "            try:\n",
    "                cv2.imwrite(path22 + items, self.process_image_for_ocr(path + items))\n",
    "            except Exception as e:\n",
    "                print(items, e)\n",
    "                raise e\n",
    "print(\"Sfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
